{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78dcfbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timofey_zheleznakov/Library/Caches/pypoetry/virtualenvs/datafusioncontest2024-public-solution-chur--LvZFGzw-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c54a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_FEATURES = [\"employee_count_nm\", \"bankemplstatus\", \"customer_age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6abe7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from objectives_slow import CoxPHObjective, CoxPHMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc8ee9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_k_fold(\n",
    "    model: Any,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    k_folds: int = 5,\n",
    "    seed = 15\n",
    ") -> Tuple[List[Any], List[pd.DataFrame], List[float]]:\n",
    "    clfs = []\n",
    "    scores = []\n",
    "    preds_full = []\n",
    "    kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in tqdm(kf.split(X=X, y=y[\"target\"])):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model.fit(\n",
    "            X=X_train, y=y_train[[\"label\"]],\n",
    "            eval_set=[(X_test, y_test[[\"label\"]])],\n",
    "            verbose=500\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        clfs += [model]\n",
    "        scores.append(\n",
    "            concordance_index(\n",
    "                y_test[\"time\"],\n",
    "                preds,\n",
    "                y_test[\"target\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        preds_full.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"user_id\": X.iloc[test_index].index,\n",
    "                    \"preds\": -preds,\n",
    "                    \"target\": y_test[\"target\"].values,\n",
    "                    \"time\": y_test[\"target\"].values\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        print(scores)\n",
    "\n",
    "    return clfs, preds_full, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5d7e9",
   "metadata": {},
   "source": [
    "## Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5bd2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv(\n",
    "    \"../transactions.csv.zip\", \n",
    "    parse_dates=[\"transaction_dttm\"], \n",
    "    low_memory=False, compression=\"zip\"\n",
    ").sort_values(\n",
    "    \"transaction_dttm\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "clients = pd.read_csv(\"../clients.csv\")\n",
    "report_dates = pd.read_csv(\"../report_dates.csv\", parse_dates=[\"report_dt\"])\n",
    "train = pd.read_csv(\"../train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d172c7e",
   "metadata": {},
   "source": [
    "## Генерация фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b06ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = clients.merge(\n",
    "    report_dates, how=\"left\", on=\"report\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.merge(\n",
    "    clients, how=\"left\", on=\"user_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[\"time\"] = transactions[\"transaction_dttm\"].apply(\n",
    "    lambda x: x.hour * 3600 + x.minute * 60 + x.second\n",
    ")\n",
    "\n",
    "transactions[\"hour\"] = transactions[\"transaction_dttm\"].dt.hour\n",
    "\n",
    "transactions[\"transaction_dttm\"] = transactions[\"transaction_dttm\"].dt.floor(\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57520dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_trans = transactions.groupby(\n",
    "    [\"user_id\"]\n",
    ").agg(\n",
    "        {\n",
    "            \"transaction_amt\":[\n",
    "                \"sum\",\n",
    "                \"min\",\n",
    "                \"max\",\n",
    "                \"median\",\n",
    "                \"std\",\n",
    "                lambda x: np.percentile(x, 5),\n",
    "                lambda x: np.percentile(x, 25),\n",
    "                lambda x: np.percentile(x, 75),\n",
    "                lambda x: np.percentile(x, 85),\n",
    "                lambda x: np.percentile(x, 95)\n",
    "            ],\n",
    "            \"mcc_code\":[\n",
    "                \"nunique\"\n",
    "            ],\n",
    "            \"currency_rk\":[\n",
    "                \"nunique\"\n",
    "            ],\n",
    "            \"transaction_dttm\": [\n",
    "                \"min\", \"max\", \"nunique\"\n",
    "            ],\n",
    "            \"time\": [\n",
    "                \"count\",\n",
    "                \"max\",\n",
    "                \"min\",\n",
    "                \"mean\",\n",
    "                \"median\",\n",
    "                \"std\"\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "count_trans.columns = count_trans.columns.map(\n",
    "    \"_\".join\n",
    ").map(lambda x: \"count_trans_\" + str(x))\n",
    "\n",
    "count_trans[\"count_trans_dates\"] = (\n",
    "    count_trans[\"count_trans_transaction_dttm_max\"] - count_trans[\"count_trans_transaction_dttm_min\"]\n",
    ").dt.days\n",
    "\n",
    "count_trans.columns = count_trans.columns.str.replace('<', '').str.replace('>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_hour_aggs = pd.pivot_table(\n",
    "    data=transactions,\n",
    "    index=\"user_id\",\n",
    "    values=\"transaction_amt\",\n",
    "    columns=\"hour\",\n",
    "    aggfunc=[\"count\", \"median\"],\n",
    "    fill_value=0\n",
    ")\n",
    "transactions_hour_aggs.columns = [\n",
    "    f\"hour_{col}\" for col in transactions_hour_aggs.columns\n",
    "]\n",
    "hour_count_cols = [\n",
    "        col for col in transactions_hour_aggs.columns\n",
    "        if \"count\" in col\n",
    "    ]\n",
    "sum_ = transactions_hour_aggs[hour_count_cols].sum(axis=1)\n",
    "for col in hour_count_cols:\n",
    "    transactions_hour_aggs[col] = transactions_hour_aggs[col] / sum_\n",
    "\n",
    "transactions_hour_aggs = transactions_hour_aggs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[\"trans_positive\"] = np.where(\n",
    "    transactions[\"transaction_amt\"] > 0, transactions[\"transaction_amt\"],np.nan\n",
    ")\n",
    "transactions[\"trans_negative\"] = np.where(\n",
    "    transactions[\"transaction_amt\"] < 0, np.abs(transactions[\"transaction_amt\"]),np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64596449",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[\"diff_days\"] = (\n",
    "    transactions[\"report_dt\"] - transactions[\"transaction_dttm\"]\n",
    ") / np.timedelta64(1, \"D\")\n",
    "\n",
    "nunique_days = transactions.groupby(\n",
    "    \"user_id\", as_index=False\n",
    ")[\"diff_days\"].nunique().rename({\"diff_days\": \"nunique_days\"}, axis=1)\n",
    "\n",
    "nunique_mcc_codes = transactions.groupby(\n",
    "    \"user_id\", as_index=False\n",
    ")[\"mcc_code\"].nunique().rename({\"mcc_code\": \"nunique_mcc_codes\"}, axis=1)\n",
    "\n",
    "nunique_currency = transactions.groupby(\n",
    "    \"user_id\", as_index=False\n",
    ")[\"currency_rk\"].nunique().rename({\"currency_rk\": \"nunique_currency\"}, axis=1)\n",
    "\n",
    "diff_days_aggs = transactions.groupby(\"user_id\")[\"diff_days\"].agg(\n",
    "    [\"min\", \"max\", \"mean\", \"std\"]\n",
    ")\n",
    "\n",
    "diff_days_aggs.columns = [\n",
    "    \"diff_days_\" + col for col in diff_days_aggs.columns\n",
    "]\n",
    "\n",
    "diff_days_aggs = diff_days_aggs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a50c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.merge(\n",
    "    diff_days_aggs[[\"user_id\", \"diff_days_min\"]], how=\"left\", on=\"user_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[\"days_groups\"] = 0\n",
    "transactions.loc[\n",
    "    transactions[\"diff_days\"] <= transactions[\"diff_days_min\"] + 10, \"days_groups\"\n",
    "] = 10\n",
    "transactions.loc[\n",
    "    transactions[\"diff_days\"] <= transactions[\"diff_days_min\"] + 5, \"days_groups\"\n",
    "] = 5\n",
    "transactions.loc[\n",
    "    transactions[\"diff_days\"] == transactions[\"diff_days_min\"], \"days_groups\"\n",
    "] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c808a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_days_groups = transactions[~transactions[\"days_groups\"].isin([0])].pivot_table(\n",
    "    index = \"user_id\",\n",
    "    values=[\"trans_positive\", \"trans_negative\"],\n",
    "    columns=[\"days_groups\"],\n",
    "    aggfunc=[\"count\", \"sum\"]\n",
    ")\n",
    "trans_days_groups.columns = [\n",
    "    f\"days_groups_{x[0]}_{x[1]}_{x[2]}\" for x in trans_days_groups.columns\n",
    "]\n",
    "trans_days_groups.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_cur_groups = transactions.pivot_table(\n",
    "    index = \"user_id\",\n",
    "    values=[\"trans_positive\", \"trans_negative\"],\n",
    "    columns=[\"currency_rk\"],\n",
    "    aggfunc=[\"count\", \"sum\"]\n",
    ")\n",
    "trans_cur_groups.columns = [\n",
    "    f\"cur_groups_{x[0]}_{x[1]}_{x[2]}\" for x in trans_cur_groups.columns\n",
    "]\n",
    "trans_cur_groups.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68885af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_days_groups = transactions[~transactions[\"days_groups\"].isin([0])].pivot_table(\n",
    "    index = \"user_id\",\n",
    "    values=[\"mcc_code\"],\n",
    "    columns=[\"days_groups\"],\n",
    "    aggfunc=[\"count\", \"nunique\"]\n",
    ")\n",
    "mcc_days_groups.columns = [\n",
    "    f\"days_groups_mcc_{x[0]}_{x[1]}_{x[2]}\" for x in mcc_days_groups.columns\n",
    "]\n",
    "mcc_days_groups.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45cce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 313 ms, total: 14.8 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transactions[\"date\"] = transactions[\"transaction_dttm\"].dt.date.astype(\"datetime64[ns]\")\n",
    "interval_trans = transactions.groupby(\"user_id\").agg({\"date\":\"unique\"}).explode(\"date\").reset_index()\n",
    "interval_trans[\"interval\"] = interval_trans.groupby(\"user_id\")[\"date\"].diff()\n",
    "interval_trans = interval_trans.dropna() \n",
    "interval_trans[\"interval\"] = interval_trans[\"interval\"].dt.days\n",
    "interval_trans = interval_trans.groupby([\"user_id\"]).agg({\"interval\": [\"last\",\"max\"]})\n",
    "interval_trans.columns = [f\"date_{x[0]}_{x[1]}\" for x in interval_trans.columns]\n",
    "interval_trans.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mcc_code = transactions.mcc_code.value_counts().to_frame().reset_index().rename(\n",
    "    columns={\"index\":\"mcc_code\", \"count\":\"count_mcc_code\"}\n",
    ")\n",
    "\n",
    "count_mcc_code20000 = np.array(\n",
    "    count_mcc_code[\n",
    "        (count_mcc_code[\"count_mcc_code\"] > 20000)\n",
    "        & (count_mcc_code[\"count_mcc_code\"] < 1000000)\n",
    "    ][\"mcc_code\"]\n",
    ")\n",
    "\n",
    "mcc_code_dumm20000 = pd.get_dummies(\n",
    "    transactions[\n",
    "        transactions[\"mcc_code\"].isin(\n",
    "            count_mcc_code20000\n",
    "        )\n",
    "    ].set_index(\"user_id\")[\"mcc_code\"]\n",
    ")\n",
    "mcc_code_dumm20000.columns = [f\"mcc_count_{x}\" for x in mcc_code_dumm20000.columns]\n",
    "mcc_code_dumm20000 = mcc_code_dumm20000.groupby([\"user_id\"]).agg(\"sum\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mcc_code10000 = np.array(\n",
    "    count_mcc_code[count_mcc_code[\"count_mcc_code\"]>=1000000][\"mcc_code\"]\n",
    ")\n",
    "mcc_code_dumm10000 = transactions[transactions[\"mcc_code\"].isin(count_mcc_code10000)][[\"user_id\",\"mcc_code\"]]\n",
    "mcc_code_dumm10000 = mcc_code_dumm10000.groupby([\"user_id\"]).agg(\"count\").reset_index().\\\n",
    "rename(columns={\"mcc_code\":\"mcc_count_big\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb2396",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mcc_code10000 = np.array(count_mcc_code[count_mcc_code[\"count_mcc_code\"]<=20000][\"mcc_code\"])\n",
    "mcc_code_dumm00001 = transactions[transactions[\"mcc_code\"].isin(count_mcc_code10000)][[\"user_id\",\"mcc_code\"]]\n",
    "mcc_code_dumm00001 = mcc_code_dumm00001.groupby([\"user_id\"]).agg(\"count\").reset_index().\\\n",
    "rename(columns={\"mcc_code\":\"mcc_count_small\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e400b5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/pf24_sj91vl7md54j4jzghs40000gn/T/ipykernel_64711/3455604399.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  percent_last[f\"num_transaction_last_{x}_days\"].fillna(.000001, inplace=True)\n",
      "/var/folders/zg/pf24_sj91vl7md54j4jzghs40000gn/T/ipykernel_64711/3455604399.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  percent_last[f\"num_transaction_before_{x}_days\"].fillna(0.000001, inplace=True)\n",
      "/var/folders/zg/pf24_sj91vl7md54j4jzghs40000gn/T/ipykernel_64711/3455604399.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  percent_last[f\"num_transaction_last_{x}_days\"].fillna(.000001, inplace=True)\n",
      "/var/folders/zg/pf24_sj91vl7md54j4jzghs40000gn/T/ipykernel_64711/3455604399.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  percent_last[f\"num_transaction_before_{x}_days\"].fillna(0.000001, inplace=True)\n",
      "/var/folders/zg/pf24_sj91vl7md54j4jzghs40000gn/T/ipykernel_64711/3455604399.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  percent_last[f\"num_transaction_last_{x}_days\"].fillna(.000001, inplace=True)\n",
      "/var/folders/zg/pf24_sj91vl7md54j4jzghs40000gn/T/ipykernel_64711/3455604399.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  percent_last[f\"num_transaction_before_{x}_days\"].fillna(0.000001, inplace=True)\n",
      "/var/folders/zg/pf24_sj91vl7md54j4jzghs40000gn/T/ipykernel_64711/3455604399.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  percent_last[f\"num_transaction_last_{x}_days\"].fillna(.000001, inplace=True)\n",
      "/var/folders/zg/pf24_sj91vl7md54j4jzghs40000gn/T/ipykernel_64711/3455604399.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  percent_last[f\"num_transaction_before_{x}_days\"].fillna(0.000001, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "percent_last = clients[[\"user_id\"]].copy()\n",
    "for x in [3, 30, 60, 90]:\n",
    "    prev = transactions[\n",
    "        transactions[\"diff_days\"] > x + 100\n",
    "    ].groupby(\"user_id\")[\"report_dt\"].agg(\n",
    "        [\"count\"]\n",
    "    ).reset_index().rename(\n",
    "        {\n",
    "            \"count\": f\"num_transaction_before_{x}_days\"\n",
    "        }, axis=1\n",
    "    )\n",
    "    last = transactions[\n",
    "        transactions[\"diff_days\"] <= x + 100\n",
    "    ].groupby(\n",
    "        \"user_id\"\n",
    "    )[\"report_dt\"].agg(\n",
    "        [\"count\"]\n",
    "    ).reset_index().rename(\n",
    "        {\"count\": f\"num_transaction_last_{x}_days\"}, axis=1\n",
    "    )\n",
    "\n",
    "    percent_last = percent_last.merge(\n",
    "        prev, how=\"left\", on=\"user_id\"\n",
    "    )\n",
    "    percent_last = percent_last.merge(\n",
    "        last, how=\"left\", on=\"user_id\"\n",
    "    )\n",
    "    percent_last[f\"num_transaction_last_{x}_days\"].fillna(.000001, inplace=True)\n",
    "    percent_last[f\"num_transaction_before_{x}_days\"].fillna(0.000001, inplace=True)\n",
    "    \n",
    "    percent_last[f\"percent_last_{x}\"] = (percent_last[f\"num_transaction_last_{x}_days\"] / \\\n",
    "    percent_last[f\"num_transaction_before_{x}_days\"]) * 100\n",
    "    percent_last.drop(f\"num_transaction_last_{x}_days\", inplace=True, axis=1)\n",
    "    percent_last.drop(f\"num_transaction_before_{x}_days\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a196790",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = pd.read_csv(\"../clients.csv\")\n",
    "df = clients.merge(\n",
    "    train, on=\"user_id\", how=\"left\"\n",
    ").merge(\n",
    "    diff_days_aggs,\n",
    "    on=\"user_id\",\n",
    "    how=\"left\"\n",
    ").merge(\n",
    "    nunique_days, on=\"user_id\", how=\"left\"\n",
    ").merge(\n",
    "    trans_days_groups, on=\"user_id\", how=\"left\"\n",
    ").merge(\n",
    "    trans_cur_groups, on=\"user_id\", how=\"left\"\n",
    ").merge(\n",
    "    mcc_days_groups, on=\"user_id\", how=\"left\"\n",
    ").merge(\n",
    "    mcc_code_dumm20000, on=\"user_id\", how=\"left\"\n",
    ").merge(\n",
    "    mcc_code_dumm10000, on=\"user_id\", how=\"left\"\n",
    ").merge(\n",
    "    mcc_code_dumm00001, on=\"user_id\", how=\"left\"\n",
    ").merge(\n",
    "    percent_last, on=\"user_id\", how=\"left\",\n",
    ").merge(\n",
    "    count_trans, on=\"user_id\", how=\"left\",\n",
    ").merge(\n",
    "    transactions_hour_aggs, on=\"user_id\", how=\"left\",\n",
    ").merge(\n",
    "    nunique_mcc_codes, on=\"user_id\", how=\"left\",\n",
    ").merge(\n",
    "    nunique_currency, on=\"user_id\", how=\"left\",\n",
    ")\n",
    "\n",
    "df[\"pl_days_trans\"] = (df[\"diff_days_max\"] - df[\"diff_days_min\"]) / df[\"nunique_days\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da42f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/pf24_sj91vl7md54j4jzghs40000gn/T/ipykernel_64711/698551816.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace(\n"
     ]
    }
   ],
   "source": [
    "df.replace(\n",
    "    {\n",
    "        \"employee_count_nm\":{\n",
    "            \"ОТ 101 ДО 500\": (100 + 500) // 2,\n",
    "            \"БОЛЕЕ 1001\": 1001,\n",
    "            \"ОТ 501 ДО 1000\": (501 + 1000) // 2,\n",
    "            \"ДО 10\": 10 // 2,\n",
    "            \"ОТ 11 ДО 50\": (11 + 50) // 2,\n",
    "            \"ОТ 51 ДО 100\": (51 + 100) // 2,\n",
    "            \"БОЛЕЕ 500\": 500,\n",
    "            \"ОТ 11 ДО 30\": (11 + 30) // 2,\n",
    "            \"ОТ 31 ДО 50\": (31 + 50) // 2\n",
    "        }\n",
    "    }, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = np.where(df[\"target\"]==0, -df[\"time\"], df[\"time\"])\n",
    "df[\"time\"] = df[\"time\"].fillna(-1)\n",
    "df[\"time\"] = df[\"time\"].astype(np.int32)\n",
    "df[\"target\"] = df[\"target\"].fillna(-1)\n",
    "df[\"target\"] = df[\"target\"].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [\n",
    "    col for col in df.columns if col not in [\n",
    "        \"user_id\",\n",
    "        \"report\",\n",
    "        \"report_dt\",\n",
    "        \"label\",\n",
    "        \"target\", \n",
    "        \"time\",\n",
    "        \"count_trans\",\n",
    "        \"count_trans_transaction_dttm_min\",\n",
    "        \"count_trans_transaction_dttm_max\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[(df[\"time\"] != -1)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d0714",
   "metadata": {},
   "source": [
    "# Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909391ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective=\"survival:cox\",\n",
    "    random_state=15,\n",
    "    reg_lambda=1.5,\n",
    "    reg_alpha=1.4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.3,\n",
    "    gamma=3,\n",
    "    min_child_weight=8,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.005,\n",
    "    n_estimators=4500\n",
    ")\n",
    "\n",
    "cb_model = cb.CatBoostRegressor(\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bylevel=0.5,\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=4500,\n",
    "    loss_function=CoxPHObjective(),\n",
    "    eval_metric=CoxPHMetric(),\n",
    "    cat_features=CAT_FEATURES,\n",
    "    use_best_model=True,\n",
    "    random_state=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa4eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-cox-nloglik:9.25226\n",
      "[500]\tvalidation_0-cox-nloglik:8.73882\n",
      "[1000]\tvalidation_0-cox-nloglik:8.70338\n",
      "[1500]\tvalidation_0-cox-nloglik:8.70013\n",
      "[2000]\tvalidation_0-cox-nloglik:8.70246\n",
      "[2500]\tvalidation_0-cox-nloglik:8.70386\n",
      "[3000]\tvalidation_0-cox-nloglik:8.70620\n",
      "[3500]\tvalidation_0-cox-nloglik:8.70701\n",
      "[4000]\tvalidation_0-cox-nloglik:8.70778\n",
      "[4499]\tvalidation_0-cox-nloglik:8.70859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:52, 52.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22943486501664123]\n",
      "[0]\tvalidation_0-cox-nloglik:9.26503\n",
      "[500]\tvalidation_0-cox-nloglik:8.72244\n",
      "[1000]\tvalidation_0-cox-nloglik:8.68263\n",
      "[1500]\tvalidation_0-cox-nloglik:8.67689\n",
      "[2000]\tvalidation_0-cox-nloglik:8.67834\n",
      "[2500]\tvalidation_0-cox-nloglik:8.67899\n",
      "[3000]\tvalidation_0-cox-nloglik:8.67955\n",
      "[3500]\tvalidation_0-cox-nloglik:8.68005\n",
      "[4000]\tvalidation_0-cox-nloglik:8.68061\n",
      "[4499]\tvalidation_0-cox-nloglik:8.68093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:46, 53.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22943486501664123, 0.2231373251775152]\n",
      "[0]\tvalidation_0-cox-nloglik:9.26928\n",
      "[500]\tvalidation_0-cox-nloglik:8.74768\n",
      "[1000]\tvalidation_0-cox-nloglik:8.71309\n",
      "[1500]\tvalidation_0-cox-nloglik:8.70768\n",
      "[2000]\tvalidation_0-cox-nloglik:8.70742\n",
      "[2500]\tvalidation_0-cox-nloglik:8.70868\n",
      "[3000]\tvalidation_0-cox-nloglik:8.71007\n",
      "[3500]\tvalidation_0-cox-nloglik:8.71090\n",
      "[4000]\tvalidation_0-cox-nloglik:8.71204\n",
      "[4499]\tvalidation_0-cox-nloglik:8.71307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:39, 53.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22943486501664123, 0.2231373251775152, 0.23186633331876927]\n",
      "[0]\tvalidation_0-cox-nloglik:9.26782\n",
      "[500]\tvalidation_0-cox-nloglik:8.73811\n",
      "[1000]\tvalidation_0-cox-nloglik:8.70713\n",
      "[1500]\tvalidation_0-cox-nloglik:8.70361\n",
      "[2000]\tvalidation_0-cox-nloglik:8.70502\n",
      "[2500]\tvalidation_0-cox-nloglik:8.70779\n",
      "[3000]\tvalidation_0-cox-nloglik:8.70888\n",
      "[3500]\tvalidation_0-cox-nloglik:8.71008\n",
      "[4000]\tvalidation_0-cox-nloglik:8.71128\n",
      "[4499]\tvalidation_0-cox-nloglik:8.71272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:32, 53.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22943486501664123, 0.2231373251775152, 0.23186633331876927, 0.22853468561008167]\n",
      "[0]\tvalidation_0-cox-nloglik:9.27565\n",
      "[500]\tvalidation_0-cox-nloglik:8.76075\n",
      "[1000]\tvalidation_0-cox-nloglik:8.72973\n",
      "[1500]\tvalidation_0-cox-nloglik:8.72769\n",
      "[2000]\tvalidation_0-cox-nloglik:8.73024\n",
      "[2500]\tvalidation_0-cox-nloglik:8.73223\n",
      "[3000]\tvalidation_0-cox-nloglik:8.73299\n",
      "[3500]\tvalidation_0-cox-nloglik:8.73495\n",
      "[4000]\tvalidation_0-cox-nloglik:8.73574\n",
      "[4499]\tvalidation_0-cox-nloglik:8.73692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:26, 53.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22943486501664123, 0.2231373251775152, 0.23186633331876927, 0.22853468561008167, 0.23751194200558415]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_models, xgb_preds, xgb_scores = get_predict_k_fold(\n",
    "    model=xgb_model,\n",
    "    X=df_train[train_columns],\n",
    "    y=df_train[[\"label\", \"target\", \"time\"]],\n",
    "    k_folds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cf6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/timofey_zheleznakov/Library/Caches/pypoetry/virtualenvs/datafusioncontest2024-public-solution-chur--LvZFGzw-py3.12/lib/python3.12/site-packages/catboost/core.py:2307: UserWarning: Failed to import numba for optimizing custom metrics and objectives\n",
      "  _check_train_params(params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9010370\ttest: 0.7839147\tbest: 0.7839147 (0)\ttotal: 244ms\tremaining: 18m 18s\n",
      "500:\tlearn: 0.9301772\ttest: 0.8054582\tbest: 0.7655177 (321)\ttotal: 2m 3s\tremaining: 16m 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [03:02, ?it/s]\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "/Users/zomb-ml-platform-msk/go-agent-21.2.0/pipelines/BuildMaster/catboost.git/catboost/private/libs/algo/tensor_search_helpers.cpp:554: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cb_models, cb_preds, cb_scores \u001b[38;5;241m=\u001b[39m \u001b[43mget_predict_k_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m999\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memployee_count_nm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 15\u001b[0m, in \u001b[0;36mget_predict_k_fold\u001b[0;34m(model, X, y, k_folds, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_index], X\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     14\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     22\u001b[0m clfs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [model]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/datafusioncontest2024-public-solution-chur--LvZFGzw-py3.12/lib/python3.12/site-packages/catboost/core.py:5807\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5805\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5807\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5808\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5809\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5810\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/datafusioncontest2024-public-solution-chur--LvZFGzw-py3.12/lib/python3.12/site-packages/catboost/core.py:2396\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2393\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2396\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2405\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/datafusioncontest2024-public-solution-chur--LvZFGzw-py3.12/lib/python3.12/site-packages/catboost/core.py:1776\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1776\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1777\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4833\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4882\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: /Users/zomb-ml-platform-msk/go-agent-21.2.0/pipelines/BuildMaster/catboost.git/catboost/private/libs/algo/tensor_search_helpers.cpp:554: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling"
     ]
    }
   ],
   "source": [
    "cb_models, cb_preds, cb_scores = get_predict_k_fold(\n",
    "    model=cb_model,\n",
    "    X=df_train.fillna(-999).astype(\n",
    "        {\n",
    "            \"employee_count_nm\": int\n",
    "        }\n",
    "    )[train_columns],\n",
    "    y=df_train[[\"label\", \"target\", \"time\"]],\n",
    "    k_folds = 5,\n",
    "    seed = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b185837",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_bled_1[\"predict\"] = predict_bled_1[\"predict\"].rank() + predict_bled_2[\"predict\"].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cea534",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_bled_1.to_csv(\"/Users/timofey_zheleznakov/Downloads/submission_blend_1.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05531b97",
   "metadata": {},
   "source": [
    "# Взвешенное усреднение Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta = pd.concat(\n",
    "    cb_preds\n",
    ").merge(\n",
    "    pd.concat(xgb_preds)[[\"user_id\", \"preds\"]],\n",
    "    suffixes=(\"_cb\", \"_xgb\"), on=\"user_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b8d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta[\"preds_cb\"] = X_meta[\"preds_cb\"].rank()\n",
    "X_meta[\"preds_xgb\"] = X_meta[\"preds_xgb\"].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Стекинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9046d50",
   "metadata": {},
   "source": [
    "## Важность фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ed072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importance(\n",
    "    features: pd.DataFrame,\n",
    "    models: List[Any],\n",
    "    height: float,\n",
    "    top_n: int = 50\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    top_n = min(top_n, df.shape[1])\n",
    "\n",
    "    fi = pd.DataFrame(index=features.columns, columns=[])\n",
    "    for i, m in enumerate(models):\n",
    "        fi[f\"m_{i}\"] = m.feature_importances_\n",
    "\n",
    "    fi = fi.stack().reset_index().iloc[:, [0, 2]]\n",
    "    fi.columns = [\"feature\", \"importance\"]\n",
    "\n",
    "    cols_ord = (\n",
    "        fi.groupby(\"feature\")[\"importance\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "        .index.tolist()[:top_n]\n",
    "    )\n",
    "\n",
    "    fi = fi[fi[\"feature\"].isin(cols_ord)]\n",
    "    print(\n",
    "        \"Всего признаков {} Усреднее по {}-ти моделям: \".format(len(cols_ord), len(models))\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, len(cols_ord) * height))\n",
    "    _ = sns.boxplot(\n",
    "        data=fi,\n",
    "        y=\"feature\",\n",
    "        x=\"importance\",\n",
    "        orient=\"h\",\n",
    "        order=cols_ord\n",
    "    )\n",
    "    return (\n",
    "        fi.groupby(by=[\"feature\"], as_index=False)[\"importance\"]\n",
    "        .median()\n",
    "        .sort_values(by=\"importance\", ascending=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee27cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats_imp = get_importance(\n",
    "    df_train[train_columns],\n",
    "    xgb_models,\n",
    "    0.20,\n",
    "    top_n=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a50279",
   "metadata": {},
   "source": [
    "# Прогноз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee647e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = df[df[\"time\"]==-1][train_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictions, cb_predictions = (\n",
    "    np.zeros(len(X_pred)), np.zeros(len(X_pred))\n",
    ")\n",
    "\n",
    "for clf in xgb_models:\n",
    "    xgb_predictions += clf.predict(X_pred[train_columns])\n",
    "\n",
    "for clf in cb_models:\n",
    "    cb_predictions += clf.predict(\n",
    "        X_pred.fillna(-999).astype(\n",
    "            {\n",
    "                \"employee_count_nm\": int\n",
    "            }\n",
    "        )[train_columns]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239930e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = df[df[\"time\"]==-1][[\"user_id\"]].copy()\n",
    "submit[\"predict\"] = pd.Series(xgb_predictions).rank().values * 0.6 + pd.Series(cb_predictions).rank().values * 0.4\n",
    "submit.to_csv(f\"submission_blend.csv\",index=False)\n",
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
